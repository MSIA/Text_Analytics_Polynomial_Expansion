{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import regexp_tokenize \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "from torchtext.data import Field, BucketIterator, TabularDataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "import dill\n",
    "import random\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_tokenizer(text):\n",
    "    text=text.replace(\"**\",\"^\")\n",
    "    return regexp_tokenize(text, \"[\\d]{1,9}|\\(|\\)|\\+|\\-|\\*|\\^|[a-z]{3}|[a-z]{1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED=1234\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"src.Field\",\"rb\")as f:\n",
    "     src=dill.load(f)\n",
    "with open(\"trg.Field\",\"rb\")as f:\n",
    "     trg=dill.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_td, test_td = TabularDataset.splits(\n",
    "    path='', validation='val_df.csv', test='test_df.csv',\n",
    "    format='csv', skip_header=False, fields=[('x', src), ('y', trg)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[71, 626]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(src.vocab),len(trg.vocab)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (val_td, test_td), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    sort_within_batch = True,\n",
    "    sort_key = lambda x: len(x.x),\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional = True)\n",
    "        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, src):\n",
    "                \n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        outputs, hidden = self.rnn(embedded)\n",
    "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)))\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
    "        super().__init__()        \n",
    "        self.attn = nn.Linear((enc_hid_dim * 2) + dec_hid_dim, dec_hid_dim)\n",
    "        self.v = nn.Linear(dec_hid_dim, 1, bias = False)\n",
    "        \n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        batch_size = encoder_outputs.shape[1]\n",
    "        src_len = encoder_outputs.shape[0]\n",
    "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
    "        \n",
    "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim = 2))) \n",
    "        attention = self.v(energy).squeeze(2)\n",
    "        \n",
    "        return F.softmax(attention, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention):\n",
    "        super().__init__()\n",
    "\n",
    "        self.output_dim = output_dim\n",
    "        self.attention = attention        \n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)        \n",
    "        self.rnn = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim)        \n",
    "        self.fc_out = nn.Linear((enc_hid_dim * 2) + dec_hid_dim + emb_dim, output_dim)        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, input, hidden, encoder_outputs):            \n",
    "        input = input.unsqueeze(0)        \n",
    "        embedded = self.dropout(self.embedding(input))        \n",
    "        a = self.attention(hidden, encoder_outputs)                \n",
    "        a = a.unsqueeze(1)        \n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)        \n",
    "        weighted = torch.bmm(a, encoder_outputs)        \n",
    "        weighted = weighted.permute(1, 0, 2)        \n",
    "        rnn_input = torch.cat((embedded, weighted), dim = 2)        \n",
    "        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))  \n",
    "        assert (output == hidden).all()\n",
    "        \n",
    "        embedded = embedded.squeeze(0)\n",
    "        output = output.squeeze(0)\n",
    "        weighted = weighted.squeeze(0)\n",
    "        \n",
    "        prediction = self.fc_out(torch.cat((output, weighted, embedded), dim = 1))        \n",
    "        return prediction, hidden.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        \n",
    "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
    "        \n",
    "        batch_size = src.shape[1]\n",
    "        trg_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        \n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "        encoder_outputs, hidden = self.encoder(src)\n",
    "                \n",
    "        input = trg[0,:]\n",
    "        \n",
    "        for t in range(1, trg_len):\n",
    "            output, hidden = self.decoder(input, hidden, encoder_outputs)\n",
    "            outputs[t] = output\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            top1 = output.argmax(1) \n",
    "            input = trg[t] if teacher_force else top1\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(src.vocab)\n",
    "OUTPUT_DIM = len(trg.vocab)\n",
    "ENC_EMB_DIM = 128\n",
    "DEC_EMB_DIM = 128\n",
    "ENC_HID_DIM = 256\n",
    "DEC_HID_DIM = 256\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "\n",
    "attn = Attention(ENC_HID_DIM, DEC_HID_DIM)\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n",
    "\n",
    "model = Seq2Seq(enc, dec, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 2,261,746 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRG_PAD_IDX = trg.vocab.stoi[trg.pad_token]\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(iterator):\n",
    "            src = batch.x\n",
    "            trg = batch.y\n",
    "            output = model(src, trg, 0) #turn off teacher forcing\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            trg = trg[1:].view(-1)\n",
    "            loss = criterion(output, trg)\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 0.019 | Test PPL:   1.019 |\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('GRUModel.pt'))\n",
    "\n",
    "test_loss = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expanded_form(tokens, src_field, trg_field, model, device, max_len = 50):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
    "    \n",
    "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
    "    \n",
    "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(1).to(device)\n",
    "    \n",
    "    src_len = torch.LongTensor([len(src_indexes)]).to(device)   \n",
    "   \n",
    "    with torch.no_grad():\n",
    "        encoder_outputs, hidden = model.encoder(src_tensor)\n",
    "        \n",
    "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
    "\n",
    "    attentions = torch.zeros(max_len, 1, len(src_indexes)).to(device)\n",
    "       \n",
    "    for i in range(max_len):\n",
    "\n",
    "        trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\n",
    "        with torch.no_grad():\n",
    "            output, hidden = model.decoder(trg_tensor, hidden, encoder_outputs)\n",
    "                    \n",
    "        pred_token = output.argmax(1).item()\n",
    "        \n",
    "        trg_indexes.append(pred_token)\n",
    "        \n",
    "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
    "            break\n",
    "\n",
    "\n",
    "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n",
    "    \n",
    "    return trg_tokens[1:], attentions[:len(trg_tokens)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src = ['(', 'a', '-', '30', ')', '*', '(', '8', '*', 'a', '-', '4', ')']\n",
      "trg = ['8', '*', 'a', '^', '2', '-', '244', '*', 'a', '+', '120']\n",
      "predicted trg = ['8', '*', 'a', '^', '2', '-', '244', '*', 'a', '+', '120']\n"
     ]
    }
   ],
   "source": [
    "i=2\n",
    "src1 = vars(test_td.examples[i])['x']\n",
    "trg1 = vars(test_td.examples[i])['y']\n",
    "print(f'src = {src1}')\n",
    "print(f'trg = {trg1}')\n",
    "expansion, attention = expanded_form(src1, src, trg, model, device)\n",
    "expansion=[x for x in expansion if x!='<eos>']\n",
    "print(f'predicted trg = {expansion}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "correct = 0, num obs.= 0\n",
      "10000\n",
      "correct = 10000, num obs.= 10876\n",
      "20000\n",
      "correct = 20000, num obs.= 21757\n",
      "30000\n",
      "correct = 30000, num obs.= 32662\n",
      "40000\n",
      "correct = 40000, num obs.= 43536\n",
      "50000\n",
      "correct = 50000, num obs.= 54394\n",
      "60000\n",
      "correct = 60000, num obs.= 65288\n",
      "70000\n",
      "correct = 70000, num obs.= 76152\n",
      "80000\n",
      "correct = 80000, num obs.= 87080\n",
      "correct = 80000, num obs.= 87081\n",
      "90000\n",
      "correct = 90000, num obs.= 97943\n",
      "100000\n",
      "correct = 100000, num obs.= 108861\n",
      "correct = 100000, num obs.= 108862\n",
      "110000\n",
      "correct = 110000, num obs.= 119802\n",
      "120000\n",
      "130000\n",
      "correct = 120000, num obs.= 130719\n",
      "140000\n",
      "correct = 130000, num obs.= 141650\n",
      "150000\n",
      "correct = 140000, num obs.= 152539\n",
      "160000\n",
      "correct = 150000, num obs.= 163372\n",
      "170000\n",
      "correct = 160000, num obs.= 174292\n",
      "180000\n",
      "correct = 170000, num obs.= 185205\n",
      "190000\n",
      "correct = 180000, num obs.= 196165\n",
      "200000\n",
      "accuracy = 0.9176454117729411\n"
     ]
    }
   ],
   "source": [
    "correct=0\n",
    "for i in range(len(test_td)):\n",
    "    if i%10000==0:\n",
    "        print(i)\n",
    "    src1 = vars(test_td.examples[i])['x']\n",
    "    trg1 = vars(test_td.examples[i])['y']\n",
    "\n",
    "    expansion, attention = expanded_form(src1, src, trg, model, device)\n",
    "    expansion=[x for x in expansion if x!='<eos>']\n",
    "\n",
    "    if expansion==trg1:\n",
    "        correct+=1\n",
    "    if correct%10000==0:\n",
    "        print('correct = '+str(correct)+', num obs.= '+str(i))\n",
    "accuracy=correct/len(test_td)\n",
    "print(f'accuracy = {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "src = x\n",
      "trg = y\n",
      "predicted trg = x^2\n",
      "src = (5-8*i)*(8*i-3)\n",
      "trg = -64*i^2+64*i-15\n",
      "predicted trg = -64*i^2+64*i-15\n",
      "src = 3*z*(z-18)\n",
      "trg = 3*z^2-54*z\n",
      "predicted trg = 3*z^2-54*z\n",
      "src = (x-2)*(7*x+27)\n",
      "trg = 7*x^2+13*x-54\n",
      "predicted trg = 7*x^2+13*x-54\n",
      "src = -6*n*(n+10)\n",
      "trg = -6*n^2-60*n\n",
      "predicted trg = -6*n^2-60*n\n",
      "src = (-2*s-28)*(4*s+7)\n",
      "trg = -8*s^2-126*s-196\n",
      "predicted trg = -8*s^2-126*s-196\n",
      "src = (-6*n-10)*(n-30)\n",
      "trg = -6*n^2+170*n+300\n",
      "predicted trg = -6*n^2+170*n+300\n",
      "src = -7*tan(j)^2\n",
      "trg = -7*tan(j)^2\n",
      "predicted trg = -7*tan(j)^2\n",
      "src = -9*j*(4*j+11)\n",
      "trg = -36*j^2-99*j\n",
      "predicted trg = -36*j^2-99*j\n",
      "src = (10-3*j)*(7*j+21)\n",
      "trg = -21*j^2+7*j+210\n",
      "predicted trg = -21*j^2+7*j+210\n",
      "src = (-6*y-23)*(y-19)\n",
      "trg = -6*y^2+91*y+437\n",
      "predicted trg = -6*y^2+95*y+437\n",
      "src = (-5*j-4)*(j+12)\n",
      "trg = -5*j^2-64*j-48\n",
      "predicted trg = -5*j^2-64*j-48\n",
      "src = (i-31)*(4*i-32)\n",
      "trg = 4*i^2-156*i+992\n",
      "predicted trg = 4*i^2-156*i+992\n",
      "src = -x*(-9*x-9)\n",
      "trg = 9*x^2+9*x\n",
      "predicted trg = 9*x^2+9*x\n",
      "src = -6*h*(h-17)\n",
      "trg = -6*h^2+102*h\n",
      "predicted trg = -6*h^2+102*h\n",
      "src = 3*o*(-2*o-19)\n",
      "trg = -6*o^2-57*o\n",
      "predicted trg = -6*o^2-57*o\n",
      "src = (16-7*n)*(24-8*n)\n",
      "trg = 56*n^2-296*n+384\n",
      "predicted trg = 56*n^2-296*n+384\n",
      "src = (-7*a-27)*(4*a-16)\n",
      "trg = -28*a^2+4*a+432\n",
      "predicted trg = -28*a^2+20*a+432\n",
      "src = (3-7*y)*(18-5*y)\n",
      "trg = 35*y^2-141*y+54\n",
      "predicted trg = 35*y^2-141*y+54\n",
      "src = (i+26)*(4*i-6)\n",
      "trg = 4*i^2+98*i-156\n",
      "predicted trg = 4*i^2+98*i-156\n",
      "src = (4-8*a)*(-3*a-1)\n",
      "trg = 24*a^2-4*a-4\n",
      "predicted trg = 24*a^2-4*a-4\n",
      "src = (y-19)*(y-16)\n",
      "trg = y^2-35*y+304\n",
      "predicted trg = y^2-35*y+304\n",
      "src = (c-10)*(c+1)\n",
      "trg = c^2-9*c-10\n",
      "predicted trg = c^2-9*c-10\n",
      "src = (22-3*i)*(i+27)\n",
      "trg = -3*i^2-59*i+594\n",
      "predicted trg = -3*i^2-59*i+594\n",
      "src = -9*i*(3*i+16)\n",
      "trg = -27*i^2-144*i\n",
      "predicted trg = -27*i^2-144*i\n",
      "src = 3*c*(24-3*c)\n",
      "trg = -9*c^2+72*c\n",
      "predicted trg = -9*c^2+72*c\n",
      "src = -4*y*(27-6*y)\n",
      "trg = 24*y^2-108*y\n",
      "predicted trg = 24*y^2-108*y\n",
      "src = -6*t*(7*t-30)\n",
      "trg = -42*t^2+180*t\n",
      "predicted trg = -42*t^2+180*t\n",
      "src = 8*(-6*sin(i)-8)*sin(i)\n",
      "trg = -48*sin(i)^2-64*sin(i)\n",
      "predicted trg = -48*sin(i)^2-64*sin(i)\n",
      "src = 3*n*(n+9)\n",
      "trg = 3*n^2+27*n\n",
      "predicted trg = 3*n^2+27*n\n",
      "src = 35*a^2\n",
      "trg = 35*a^2\n",
      "predicted trg = 35*a^2\n",
      "src = 8*o*(o+5)\n",
      "trg = 8*o^2+40*o\n",
      "predicted trg = 8*o^2+40*o\n",
      "src = (t-6)*(8*t+30)\n",
      "trg = 8*t^2-18*t-180\n",
      "predicted trg = 8*t^2-18*t-180\n",
      "src = 7*a*(4*a+3)\n",
      "trg = 28*a^2+21*a\n",
      "predicted trg = 28*a^2+21*a\n",
      "src = (-8*t-28)*(7*t-24)\n",
      "trg = -56*t^2-4*t+672\n",
      "predicted trg = -56*t^2-4*t+672\n",
      "src = (z+10)*(2*z+6)\n",
      "trg = 2*z^2+26*z+60\n",
      "predicted trg = 2*z^2+26*z+60\n",
      "src = (3-9*a)*(24-2*a)\n",
      "trg = 18*a^2-222*a+72\n",
      "predicted trg = 18*a^2-222*a+72\n",
      "src = (n+17)*(2*n+17)\n",
      "trg = 2*n^2+51*n+289\n",
      "predicted trg = 2*n^2+51*n+289\n",
      "src = (1-7*a)*(6*a+30)\n",
      "trg = -42*a^2-204*a+30\n",
      "predicted trg = -42*a^2-216*a+30\n",
      "src = t*(4*t-4)\n",
      "trg = 4*t^2-4*t\n",
      "predicted trg = 4*t^2-4*t\n",
      "src = (14-3*h)*(3*h+22)\n",
      "trg = -9*h^2-24*h+308\n",
      "predicted trg = -9*h^2-24*h+308\n",
      "src = -7*i*(-2*i-22)\n",
      "trg = 14*i^2+154*i\n",
      "predicted trg = 14*i^2+154*i\n",
      "src = (-9*o-5)*(-8*o-32)\n",
      "trg = 72*o^2+328*o+160\n",
      "predicted trg = 72*o^2+328*o+160\n",
      "src = (26-5*o)*(4*o-17)\n",
      "trg = -20*o^2+189*o-442\n",
      "predicted trg = -20*o^2+189*o-442\n",
      "src = x*(x+26)\n",
      "trg = x^2+26*x\n",
      "predicted trg = x^2+26*x\n",
      "src = (13-6*s)*(2*s+27)\n",
      "trg = -12*s^2-136*s+351\n",
      "predicted trg = -12*s^2-136*s+351\n",
      "src = (-3*c-11)*(2*c+7)\n",
      "trg = -6*c^2-43*c-77\n",
      "predicted trg = -6*c^2-43*c-77\n",
      "src = 3*s*(25-3*s)\n",
      "trg = -9*s^2+75*s\n",
      "predicted trg = -9*s^2+75*s\n",
      "src = (-9*i-5)*(i-30)\n",
      "trg = -9*i^2+265*i+150\n",
      "predicted trg = -9*i^2+265*i+150\n",
      "src = (25-c)*(3*c+31)\n",
      "trg = -3*c^2+44*c+775\n",
      "predicted trg = -3*c^2+44*c+775\n",
      "src = (31-k)*(6*k-6)\n",
      "trg = -6*k^2+192*k-186\n",
      "predicted trg = -6*k^2+192*k-186\n",
      "accuracy = 0.9215686274509803\n"
     ]
    }
   ],
   "source": [
    "correct=0\n",
    "for i in range(len(test_td)-199950):\n",
    "    if i%10000==0:\n",
    "        print(i)\n",
    "    src1 = vars(test_td.examples[i])['x']\n",
    "    trg1 = vars(test_td.examples[i])['y']\n",
    "    \n",
    "    print(\"src = \" + ''.join(src1))\n",
    "    print(\"trg = \" + ''.join(trg1))\n",
    "\n",
    "    expansion, attention = expanded_form(src1, src, trg, model, device)\n",
    "    expansion=[x for x in expansion if x!='<eos>']\n",
    "    print(\"predicted trg = \" +''.join(expansion))\n",
    "\n",
    "    if expansion==trg1:\n",
    "        correct+=1\n",
    "    \n",
    "accuracy=correct/(len(test_td)-199950)\n",
    "print(f'accuracy = {accuracy}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sri1",
   "language": "python",
   "name": "sri1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
